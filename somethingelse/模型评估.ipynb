{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型评估\n",
    "## 概述\n",
    "模型评估只要分为在线和离线两阶段。针对分类、排序、回归、序列预测等不同类型的机器学习问题，评估选择有所不同，**知道每种评估指标的精确定义，有针对性地选择合适的评估指标、根据评估指标的反馈进行模型调整**，这些都是模型评估阶段的关键问题，也是一个合格的算法工程师应当具备的基本功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各评估指标的含义和局限性\n",
    "### 准确度\n",
    "准确度是指分类正确的样本栈总样本个数，即$$Acuracy=\\frac{n_{correct}}{n_{total}}$$\n",
    "其中，$n_{correct}$是被正确分类的样本个数，$n_{total}$是总样本个数。\n",
    "#### 准确度局限性\n",
    "假设场景：不同类别的样本比例非常不均衡，例如负样本占99%，正样本占1%。模型判断全部样本为证样本，那么准确率都有99%了，即便模型把全部正样本都预测错误。  \n",
    "解决方案：使用**平均准确率**（每个类别下的样本准确率的算数平均）作为模型评估指标。  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 精确度与召回率\n",
    "**精确度指分类正确的正样本个数占分类器判定为正样本的样本个数的比例**  \n",
    "**召回率是指分类正确的正样本个数占真正正样本个数的比例**  \n",
    "显然精确度和召回率是一个**既矛盾又统一**的指标。例如，为提高精确度，我们选择把那些不是很有把握为正样本的样本舍弃掉，由于这样过于“保守”而漏掉需要“没有把握”的正样本，会降低召回率。  \n",
    "实际分析问题中，我们需要针对模型结果判断是哪个指标出现了问题，再进行调整。而为了综合判断一个模型的好坏，不仅需要观察不同top N下的Precision@N和Recall@N，还需要绘制模型的**P-R曲线**。  \n",
    "### P-R曲线\n",
    "P-R曲线横轴是召回率，纵轴是精确率。通常，只用某个点对应的精确率和召回率不能全面地衡量模型的性能，只有通过P-R曲线的整体表现，才能对模型作出一个更全面的评价。  \n",
    "除此之外，还有**F1 score**和**ROC**曲线也能综合地反映一个排序模型的性能。  \n",
    "### F1 score曲线\n",
    "F1 score是精确率和召回率的调和平均值。$$F1=\\frac{2*precision*recall}{precision*recall}$$\n",
    "### ROC曲线\n",
    "ROC曲线的横坐标是假阳性率（False Positive Rate FPR）,纵坐标为真阳性率（True Positive Rate TPR）。$$FPR=\\frac{FP}{N}$$ \n",
    "\n",
    "$$TPR=\\frac{TP}{P}$$\n",
    "上式中，P是真实的正样本数量，N是真实的负样本数量，TP是P个正样本中被分类器预测为正样本的个数，FP是N个负样本中被分类器预测为正样本的个数。  \n",
    "如何绘制ROC曲线，首先需要引进**截断点**，截断点是指区分正负预测结果的阈值。（例如在二值分类问题上，模型一般输出的是预测样本为正的概率，此时指定概率大于等于0.9才能输出是正样本，0.9即此问题上指定的截断点）。  \n",
    "通过动态调整截断点，从最高的得分开始逐渐调整到最低分，每个截断点对应着一个FPR和TPR，在ROC图上绘制每个截断点对应的位置，连接所有点即得最终的ROC曲线。  \n",
    "#### AUC\n",
    "**AUC是指ROC曲线下的面积大小**，计算AUC仅需计算基于ROC横轴的积分即可，该值能够量化地反映基于ROC曲线衡量出的模型性能。\n",
    "### ROC曲线和P-R曲线对比\n",
    "当正负样本的分布发生变化，ROC曲线的形状基本保持不变，而P-R曲线的形状一般会发生比较剧烈的变化。  \n",
    "这个特点让ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。在实际生产中，正负样本往往很不均衡，这个时候显然选择ROC曲线能更合适，然而并不是ROC曲线一定比P-R曲线更好，例如需要更多地看到模型在特定数据集上的表现，P-R曲线能够更直观地反映其性能。因此选择何种曲线需要依据需求来决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE指标 \n",
    "**RMSE指标常用来衡量回归模型的好坏**，RMSE公式为$$RMSE=\\sqrt{\\frac{\\sum_{i-1}^{n}(y_{i}-\\hat{y_{i}})^{2}}{n}}$$\n",
    "其中，$y_{i}$为第i个样本的真实值，$\\hat{y_{i}}$为第i个样本点的预测值，n是样本点个数。  \n",
    "根据公式，RMSE反映的是回归模型预测值和真实值的偏离程度，但是在实际问题中，如果存在个别偏离程度很大的离群点，即便这些离群点很少，也能使得RMSE值变得很差。实际中，在流量预估此外场景下，噪声点确实很容易产生。  \n",
    "针对此类离群点情况，可以有如下三种解决方案。  \n",
    "1 认为此类离群点是噪声点，在数据预处理阶段把此类噪声点去掉。\n",
    "2 认为这些离群点不是噪声点，则需要进一步加强模型的预测能力，把离群点产生的机制建模进去。  \n",
    "3 寻找一个更合适的指标来评估模型，例如**平均绝对百分比误差MAPE**$$MAPE=\\sum_{i=1}^{n}\\left | \\frac{y_{i}-\\hat{y_{i}}}{y_{i}} \\right | *\\frac{100}{n}$$\n",
    "相比于RMSE，MAPE相当于把每个点的误差进行归一化，降低了个别离群点带来的绝对误差的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 余弦距离和欧式距离\n",
    "#### 什么是余弦距离\n",
    "在机器学习中，通常将特征表示为向量的形式，因此在分析两个特征向量的相似度时常常用余弦相似度来表示。余弦相似度取值范围：[-1,1]，相同的特征向量余弦相似度为1.将1-余弦相似度即为余弦距离。因此余弦距离取值为[0,2]，相同两个向量余弦距离为0。\n",
    "#### 余弦距离并非严格意义上的距离\n",
    "**距离的定义**：在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理成立（正定性、对称性、三角不等式），则该实数可称为这对元素的距离。可证得余弦距离符合正定性、对称性，但不符合三角不等式。\n",
    "#### 余弦距离和欧式距离的适用范围\n",
    "余弦相似度定义为$$\\cos (A,B=\\frac{A\\cdot B}{\\left \\| A \\right \\|_{2}\\cdot \\left \\| B \\right \\|_{2}}$$\n",
    "余弦相似度关心的是向量之间的角度关系，欧式距离关心的是绝对大小。余弦相似度在高维时仍然保持“相似为1，相反为0”的特性，而欧式距离受维度影响较明显，范围不固定，含义也比较含糊。举例：统计两部剧用户的观看行为，用户A观看向量为(0,1)，用户B观看向量为(1,0)。其余弦距离相差很大，欧式距离相差很小。当我们考虑两者的视频偏好时，更关注相对差异，因此会采用余弦距离，而非绝对距离的欧式距离。当分析用户的活跃度时，以登录次数和登录时长为特征时，用户A为(1,10)，用户B为(10,100)。余弦距离很小，但显然两者的活跃度差异很大，应该选择欧式距离来衡量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估中的验证方法\n",
    "**Holdout检验**  \n",
    "按比例将原始样本集随机划分为训练集和测试集，例如将70%的样本用作训练，30%样本用作测试。30%用于模型评估，包括绘制ROC曲线、计算精度、召回率等指标来评估模型。  \n",
    "**交叉检验**  \n",
    "Holdout检验中验证集计算出来的指标往往跟原始数据集的划分有很大关系，为消除随机性，引入“交叉验证”。将全部样本划分为k个大小相等的样本子集，依次遍历k个子集，每次将该子集作为验证集，其余为训练集，进行模型训练与评估，遍历完后把**k次评估指标的平均值作为最终的评估指标**。在实际中k通常取10."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "默认的kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
